{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7cccde",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "# este comando executa o notebook do caminho abaixo, dentro deste notebook. Ele pode estar na cloud, ou outro lugar, diretório e etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f12953",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Users/adolfoacarlos@gmail.com/secrets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897f976",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = AZURE_SQL_USERNAME ## USER NAME DO DATABASE\n",
    "password = AZURE_SQL_PASSWORD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c626255",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f7f2e",
   "metadata": {},
   "source": [
    "# ler a tabela que está na Azure -\n",
    "# utilizar a sparksession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed8750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8893d72",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2560a3",
   "metadata": {},
   "source": [
    "url da conexão lá na azure\n",
    "codifike-server  = nome do servidor\n",
    "spark-sql = nome do banco de dados\n",
    "nos projetos em geral essas duas variáveis são utilizadas e compõe a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"jdbc:sqlserver://codifike-server.database.windows.net:1433;databaseName=spark-sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caf789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47561a46",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d27f2",
   "metadata": {},
   "source": [
    "opções de conexão \n",
    "é o nome do usuário, senha do usuário e  o driver que está sendo utilizado , está em formato de dicionário para facilitar\n",
    "poderia exitir outros tipos de conexão, como single sign on, e etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8cd290",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_properties = {\n",
    "    \"user\": username,\n",
    "    \"password\": password,\n",
    "    \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57f221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a05f095c",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7dd608",
   "metadata": {},
   "source": [
    "ler a tabela do banco de dados e armazenar os dados em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f011fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.jdbc (url,'sale.user',properties=connection_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9a142",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38204d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d928b",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29826ad5",
   "metadata": {},
   "source": [
    "antes de fazer a leitura da tabela, é necessário primeiro criar uma tabela temporária aqui para \"armazenar as informações que serão lidas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b83d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('users_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314fe61",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3672042",
   "metadata": {},
   "source": [
    "MAGIC %sql\n",
    "MAGIC -- fazer um join da tabela, lendo na nuvem da azure através do databricks\n",
    "MAGIC\n",
    "MAGIC SELECT * FROM users_table limit 10\n",
    "MAGIC\n",
    "MAGIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4233aef",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19726b47",
   "metadata": {},
   "source": [
    "ler a tabela novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0325a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.spark.read.jdbc(url,\"sale.sales\",properties = connection_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c887516",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria novamente a tabela temporária\n",
    "df.createOrReplaceTempView('sales_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f423d",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3d41e",
   "metadata": {},
   "source": [
    "MAGIC %sql\n",
    "MAGIC\n",
    "MAGIC SELECT * FROM sales_table limit 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89d3a1",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41f387",
   "metadata": {},
   "source": [
    "MAGIC %sql\n",
    "MAGIC --fazendo join\n",
    "MAGIC\n",
    "MAGIC SELECT u.first_name, u.last_name, s.sale_date, s.sale_amount\n",
    "MAGIC FROM  users_table as u\n",
    "MAGIC INNER JOIN sales_table s\n",
    "MAGIC ON (u.user_id = s.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f1a1a",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2edaab",
   "metadata": {},
   "source": [
    "pegar o resultado de um select , ou um querie e gravar novamente no banco de dados\n",
    "usar o python , para conseguir gravar o resultado da query em uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2424c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "query  = \"\"\"\n",
    "SELECT u.first_name, u.last_name, s.sale_date, s.sale_amount\n",
    "FROM  users_table as u\n",
    "INNER JOIN sales_table s\n",
    "ON (u.user_id = s.user_id)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683b7f4",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executa em um novo dataframe, o resultado da minha querye\n",
    "result_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9c1bd",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e584cf",
   "metadata": {},
   "source": [
    "escreve no banco\n",
    "passar o nome da tabela onde eu quero gravar junto com o schema\n",
    "o modo overwrite deve ser utilizado apenas se a tabela não existir, caso a tabela EXISTA, usar o modulo \"append\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.write.jdbc(url, \"sale.sales_report\", mode= \"overwrite\", properties=connection_peoperties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459fc24",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea435e0",
   "metadata": {},
   "source": [
    "código para usar as secrets da azure para databricks full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ClientSecretCredential\n",
    "from azure.keyvault.secrets import SecretClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a0447",
   "metadata": {},
   "source": [
    "key vault é como um cofre de segurança digital, para que isso não precise ser gravados e guardados em lugares inseguros, como máquinas locais e tudo fique protegido por criptografia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina suas credenciais do Azure , são como senhas, chaves e tokens de acesso ( para segurança)\n",
    "tenant_id = 'AZURE-ID-TENANT' # representa a \"organização na azure\"\n",
    "client_id = 'AZURE-ID-CLIENTE' # id do cliente que está tentando acessar \n",
    "client_secret = 'AZURE-ID-CLIENTE' # senha do id do cliente que está tentando acessar\n",
    "vault_url = \"https://codifike-spark-chaves.vault.azure.net\" # CAMINHO ONDE ESTÃO AS MINHAS SECRETS # endereço do cofre onde estão armazenadas minhas chaves de acesso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autentique-se e crie um cliente\n",
    "credential = ClientSecretCredential(tenant_id=tenant_id , client_id=client_id,client_secret=client_secret)\n",
    "client = SecretClient(vault_url=vault_url , credential = credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac1a07b",
   "metadata": {},
   "source": [
    "Recupere os segredos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc92566",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_username = client.get_secret('AZURE-SQL-USERNAME').value\n",
    "db_password = client.get_secret('AZURE-SQL-PASSWORD').value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b365705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca90c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
