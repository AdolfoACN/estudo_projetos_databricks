{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd36585",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "MAGIC %md\n",
    "MAGIC Neste notebook, analisaremos os e-mails, e treinaremos o melhor modelo, para verificar se os emails referidos se tratam de SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b462262",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b788ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/FileStore/tables/classification.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88dae6a",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31331a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e90a33",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar as bibliotecas que estaremos trabalhando\n",
    "# Estamos selecionando 3 modelos de classificação, para definir, qual melhor modelo\n",
    "import logging\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier , DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87794242",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Configura o logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c747619",
   "metadata": {},
   "source": [
    "Definir as colunas features e destino(lable) para serem analisadas pelos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dadbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col =['word_count','has_attachment','is_reply']\n",
    "target_col = 'is_spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "logger.info(\"Carregando os dados..\")\n",
    "data = spark.read.format('csv').option('header',True).option('inferSchema',True).load('/FileStore/tables/classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo as colunas\n",
    "logger.info(\"Preparando os dados...\") \n",
    "assembler = VectorAssembler(inputCols=features_col,outputCol='features')\n",
    "data = assembler.transform(data).select('features',target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75077ef6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "# randomsplit define a divisão do arquivo de dados que vai ser treinada e que vai ser guardada\n",
    "# seed controla a alteração ou não do arquivo, os numeros e pesos continuarão os mesmos\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b278af",
   "metadata": {},
   "source": [
    "Treine os modelos utilizando os dados\n",
    "treinando os 3 modelos de uma vez, armazenando tudo na variável \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Treinando os modelos...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "  'Logistic_Regression': LogisticRegression(featuresCol='features',labelCol=target_col),\n",
    "  'Random_Forest': RandomForestClassifier(featuresCol='features',labelCol=target_col),\n",
    "  'Decision_Tree': DecisionTreeClassifier(featuresCol='features',labelCol=target_col),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77827f",
   "metadata": {},
   "source": [
    "Depois do treinamento dos modelos, temos que avaliar qual o melhor modelo utilizado na busca dos dados\n",
    "Busca o melhor. na variável evaluator avaliando todas as saídas dos modelos e vai verificar qual vai ser a melhor\n",
    "utilizando a métrica f1 scrore, que combina a precisão e record, a média harmônica ( essa métrica é bem utilizada em modelos que podem estar desbalanceados, ) deixar 45 a 50 % para cada uma das saídas\n",
    "1 indica desempenho perfeito e 0 indica um desempenho muito ruim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b181144",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=target_col,predictionCol=\"prediction\",metricName=\"f1\")\n",
    "best_model = None\n",
    "best_f1_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    logger.info(f\"Treinando e avaliando o modelo {name}... \")\n",
    "    trained_model = model.fit(train_data)\n",
    "    predictions = trained_model.transform(test_data)\n",
    "    f1_score = evaluator.evaluate(predictions)\n",
    "    logger.info(f\"F1 Score do modelo {name}: {f1_score}\")\n",
    "    \n",
    "    if f1_score > best_f1_score:\n",
    "      best_f1_score = f1_score\n",
    "      best_model = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40641d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"O Modelo com o melhor desempenho é {best_model} com F1 Score de {best_f1_score}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee27e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
