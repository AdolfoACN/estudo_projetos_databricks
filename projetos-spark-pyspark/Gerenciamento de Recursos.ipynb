{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8feb317a",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "# Configuração da parte de memória que o spark vai utilizar para processamento\n",
    "memória utilizando apenas o NOTEBOOK\n",
    "driver é o processo responsável por gerenciar a execução do aplicativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.conf.set('spark.driver.memory','2g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715715d6",
   "metadata": {},
   "source": [
    "caso não esteja utilizando o notebook, acesso via IDE, pycharm e etc\n",
    "configuração via IDE\n",
    "o notebook não precisa criar uma sparksession, o objeto spark , ao criar sobe as informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfb724",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('myapp')\\\n",
    "    .config('spark.driver.memory','2g')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8660fa8",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ae65d",
   "metadata": {},
   "source": [
    "Altera a memória apenas do EXECUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb3b85",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%spark.conf.set('spark.executor.memory','2g') # via notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62df1bd",
   "metadata": {},
   "source": [
    "via IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('myapp')\\\n",
    "    .config('spark.executor.memory','2g')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c269f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4753f6f4",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404887a3",
   "metadata": {},
   "source": [
    "configurar a CPU - definir a quantidade de cores/nucleos para cada worker, quantidade de núcleos de processadores para configurar os recursos do seu cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657b212",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# pelo notebook-databricks \n",
    "%spark.conf.set('spark.executor.cores','4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando uma IDE\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('myapp')\\\n",
    "    .config('spark.executor.cores','4')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acac074e",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303b6c0",
   "metadata": {},
   "source": [
    "Configurar o DISCO # O diretório onde são armazenados os dados temporários utilizados nos processamento\n",
    "EXTREMAMENTE NÃO RECOMENDÁVEL( SE PUDER , NÃO FAÇA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79147b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# via notebook - databricks\n",
    "spark.conf.set('spark.local.dir',\"path/to/directory\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a6b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af3fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13384af2",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a52e0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ALTERANDO CONFIGURAÇÃO SPARK-ENV.SH\n",
    "# BUSCAR INFORMAÇÕES NO GITHUB DO SPARK\n",
    "export SPARK_HOME=opt/spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5c644",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d72344",
   "metadata": {},
   "source": [
    "BUSCAR NO GITHUB DO SPARK NA PASTA conf\n",
    "arquivo: spark-defaults.conf.template"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
