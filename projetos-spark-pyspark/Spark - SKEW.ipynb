{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e428552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# Balanceamento de Carga , quando uma ou mais partições recebem mais carga/quantidade de dados, processo conhecido como Skewness/assimetria de dados\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os Dataframes de exemplo\n",
    "data1 = [(\"A\",1),(\"B\",2),(\"C\",3),(\"D\",4)]\n",
    "data2 = [(\"A\",100),(\"A\",101),(\"A\",102),(\"B\",200),(\"C\",300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c277436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(data1, [\"Key\",\"Value\"])\n",
    "df2 = spark.createDataFrame(data2, [\"Key\",\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join que causa skewness\n",
    "joined_df = df1.join(df2,\"Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1039c6b",
   "metadata": {},
   "source": [
    "Exibindo os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe3a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a257ed32",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261c11b",
   "metadata": {},
   "source": [
    "Contando as ocorrências de cada chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed93160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_count = df2.groupBy(\"Key\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603f7db",
   "metadata": {},
   "source": [
    "Convertendo para pandas DataFrame para visualização em gráficos via matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df2_count = df2_count.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um gráfico de barras, para visualizar a contagem do dataframe pandas_df2_count\n",
    "plt.figure(figsize= (8,6))\n",
    "plt.bar(pandas_df2_count[\"Key\"],pandas_df2_count[\"count\"] ) # eixo x e eixo y\n",
    "plt.xlabel (\"Key\") # Lable do eixo x\n",
    "plt.ylabel(\"Count\") # Lable do eixo y\n",
    "plt.title(\"Distribuição dos Dados Antes de realizar o Join\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f965291",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef69e00",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Utilizando a TÉCNICA REPARTITION\n",
    "MAGIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36863c1",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee45960",
   "metadata": {},
   "source": [
    "tamanho dos dados / ambiente da aplicação = número de partições\n",
    "Reparticionamento utilzando função repartition, \n",
    "informa o número de partições\n",
    "verificar a distribuição dos dados. verificar a contagem da memória, o tamanho do arquivo , a quantidade de partições deve ser múltiplo em relação ao tamanho dos cores.\n",
    "esse comando faz o shuffle, reposiciona os dados entre os nós dos clusters\n",
    "operação + cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41657f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_repartitioned = df1.repartition(2,'Key') # número de partições / 'Campo utilizado para a chave'\n",
    "df2_repartitioned = df2.repartition(2,'Key') # número de partições / 'Campo utilizado para a chave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = df1_repartitioned.join(df2_repartitioned,'Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01856898",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214a1b6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87738a43",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136407d",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Usando a técnica SALTING\n",
    "MAGIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76900b",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef9797",
   "metadata": {},
   "source": [
    "o salting, são valores aleatórios, que podem ser usados como chave de particionamento, facilita a identificação única dos registros, quando o join é realizado\n",
    "de maneira aleatória ( randomica função rand(), ele acrescenta valores numéricos a nova coluna criada)\n",
    "Risco: quando o dataframe menor é transformado em um dataframe maior , deve verificar se a performance melhora, caso contrário, usar outra técnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bfd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, rand\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_factor = 5 # Exemplo: Adicionar 5 valores Salting diferentes( valores entre 0 e 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde91c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionaldo o salt apenas em df2(Maior Dataframe)\n",
    "df2_with_salt =df2.withColumn(\"salt\",(rand()* salt_factor).cast(\"int\")) # criando uma coluna nova para acrescentar o salting\n",
    "display(df2_with_salt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61942532",
   "metadata": {},
   "source": [
    "Expandindo o df1 (dataframe menor), para incluir todas as combinações possíveis de salting\n",
    "no dataframe menor, você cria na coluna salt, todas as chaves aleatórias, para que no momento em que se for\n",
    "fazer o join, exista a referência ( código ) nos dois dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac62595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_expanded = df1.crossJoin(spark.range(salt_factor).toDF(\"salt\"))\n",
    "display (df1_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a46be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2643a0a7",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54053ccb",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC AUMENTANDO O NÚMERO DE PARTIÇÕES PARA BALANCEAR O PARTICIONAMENTO SHUFFLE.PARTITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42accd5d",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e31b7",
   "metadata": {},
   "source": [
    "comando para aumentar o número de partições\n",
    "PARA EXECUTAR ESSA TÉCNICA, SERÁ NECESSÁRIO REALIZAR UM RESET RÁPIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62067508",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions','500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d00bee",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79821385",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC à partir do spark 3.0 adaptative query execution\n",
    "MAGIC ajustar automaticamente a quantidade de suffle partitions, baseada no tamanho e estágio do processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28315dc",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7ae4f",
   "metadata": {},
   "source": [
    "deixa o spark habilitado para o spark ajudar a otimizar no balanceamento do particionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0e7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptative.enabled\",\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e0834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
