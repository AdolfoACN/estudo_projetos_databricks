{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "df = spark.read.csv('/FileStore/tables/imoveis-4.csv', header =True, inferSchema =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d10ac",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a740567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1df34",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b199b85",
   "metadata": {},
   "source": [
    "treinamento do dataframe dentro da biblioteca de machine learning\n",
    "importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6a12e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Configurando o logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger (__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf08f7",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee930417",
   "metadata": {},
   "source": [
    "# carregar os dados para treinamento utilizando a biblioteca de logger para usar a informação do logger que acompanha a execução dos comandos, mostra na tela o passo executado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info (\"Carregando os dados de treinamento...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec56f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.format('csv').option('header',True).option('inferSchema',True).load('/FileStore/tables/imoveis-4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17304979",
   "metadata": {},
   "source": [
    "definindo as colunas das features(recursos) e lable(destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58373fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Definindo colunas de features e lable...\")\n",
    "features_col = ['rooms','bathroom','size'] # features\n",
    "target_col = 'price' # lable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7cd9d",
   "metadata": {},
   "source": [
    "Convertendo as colunas em um vetor ( vector) usando vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Preparando os dados para treinamento...\")\n",
    "assembler = VectorAssembler(inputCols=features_col, outputCol='features')\n",
    "train_data = assembler.transform(train_data).select('features',target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e82b1b",
   "metadata": {},
   "source": [
    "treinar o modelo em regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Treinando o modelo de regressão linear...\")\n",
    "lr = LinearRegression(featuresCol='features',labelCol=target_col,regParam=0.01)\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da2a15",
   "metadata": {},
   "source": [
    "fazer parte da previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da508068",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Fazendo previsões com o modelo treinado...\")\n",
    "new_data = spark.createDataFrame([(3, 2, 150)], ['rooms', 'bathroom', 'size'])\n",
    "new_data = assembler.transform(new_data).select('features')\n",
    "prediction = lr_model.transform(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9df12",
   "metadata": {},
   "source": [
    "Mostrar o valor da previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ed74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = prediction.first().prediction\n",
    "logger.info(\"O valor previsto é:\" + str(predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d379c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514fc08b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
