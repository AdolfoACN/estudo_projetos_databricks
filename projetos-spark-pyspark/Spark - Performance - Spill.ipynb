{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7887bf15",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "MAGIC %md\n",
    "MAGIC Spill - \n",
    "MAGIC Quando a quantidade de Dados, excede a quantidade de memória disponível, e quando isso acontece, o spark, utiliza temporariamente o disco para trabalhar e processar os dados ( o que deixa o processamento mais lento)\n",
    "MAGIC\n",
    "MAGIC Quando trabalhamos com o Apache Spark, uma das questões que pode impactar a performance é o \"spill\" de dados para o disco. O spill acontece quando os dados em memória excedem a capacidade disponível e o Spark é forçado a escrever esses dados temporariamente no disco. Isso pode ocorrer durante operações de shuffle ou quando o cache de RDD/DataFrame é grande demais para caber na memória. O spill para o disco pode significativamente desacelerar as operações, já que a leitura e a escrita em disco são muito mais lentas do que operações em memória.\n",
    "MAGIC\n",
    "MAGIC Melhores práticas para evitar :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643e20a",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25dafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentar a quantidade de memória dos executers (executer memory)\n",
    "# alterando para 4gb\n",
    "# \n",
    "#  # utilizando o notebook\n",
    "%spark.conf.set(\"spark.executor.memory\",\"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Utilizando uma sessão Spark com mais memória - IDE\n",
    "# Chamando no objeto Spark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a966b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"High Memory App\") \\\n",
    "  .config(\"spark.executor.memory\",\"4g\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf708d",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad18197",
   "metadata": {},
   "source": [
    "Aumentar a fração de memória para as operações de shuffle, ele pode podencialmente reduzir o Spill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark.conf.set(\"spark.shuffle.memoryFracion\",\"0.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff61da",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir a paralelização\n",
    "# Garante que cada atividade paralela/processamento realizado, vai receber um pouco mais de memória\n",
    "# reduzindo o número de partições\n",
    "df = df.coalesce(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1a219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594055af",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a0888",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Memory Fraction\n",
    "# Define a fração de memória que está dentro da máquina (jvm) -- estrutura do spark -- spark puro\n",
    "# usando notebook\n",
    "%spark.conf.set(\"spark.memoryFracion\",\"0.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0dfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# utilizando ide\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7df3f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"High Memory App\") \\\n",
    "  .config(\"spark.memoryFracion\",\"0.7\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd3724",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cffa5f3",
   "metadata": {},
   "source": [
    "Melhorar o tamanho do buffer do shuffle\n",
    "O Spark, utiliza alguns buffers, para agrupar os dados/registros, antes de realizar o SPILL\n",
    "Aumentando o tamanho, pode evitar o Spill\n",
    "o padrão do buffer é 32k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852366c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%spark.conf.set(\"spark.shuffle.file.buffer\",\"128k\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
